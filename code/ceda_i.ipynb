{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0d674e",
   "metadata": {},
   "source": [
    "As usual, we'll start with cleaning and attempt to EDA at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9544a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca7092e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190757, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>segment</th>\n",
       "      <th>category</th>\n",
       "      <th>channel</th>\n",
       "      <th>region</th>\n",
       "      <th>pack_type</th>\n",
       "      <th>price_unit</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>delivery_days</th>\n",
       "      <th>stock_available</th>\n",
       "      <th>delivered_qty</th>\n",
       "      <th>units_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Retail</td>\n",
       "      <td>PL-Central</td>\n",
       "      <td>Multipack</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>128</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Retail</td>\n",
       "      <td>PL-North</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Retail</td>\n",
       "      <td>PL-South</td>\n",
       "      <td>Carton</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>161</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Discount</td>\n",
       "      <td>PL-Central</td>\n",
       "      <td>Single</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Discount</td>\n",
       "      <td>PL-North</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>204</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     sku     brand    segment category   channel      region  \\\n",
       "0  2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk    Retail  PL-Central   \n",
       "1  2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk    Retail    PL-North   \n",
       "2  2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk    Retail    PL-South   \n",
       "3  2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk  Discount  PL-Central   \n",
       "4  2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk  Discount    PL-North   \n",
       "\n",
       "   pack_type  price_unit  promotion_flag  delivery_days  stock_available  \\\n",
       "0  Multipack        2.38               0              1              141   \n",
       "1     Single        1.55               1              3                0   \n",
       "2     Carton        4.00               0              5              118   \n",
       "3     Single        5.16               0              2               81   \n",
       "4     Single        7.66               0              4              148   \n",
       "\n",
       "   delivered_qty  units_sold  \n",
       "0            128           9  \n",
       "1            129           0  \n",
       "2            161           8  \n",
       "3            114           7  \n",
       "4            204          12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('../data/FMCG_2022_2024.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('.', '') #Clean the titles for ease of coding\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570fb5ed",
   "metadata": {},
   "source": [
    "All right, we have a formal 190kish sales records to look at. I'm unsure if the default order is appropriate to have sku first, but I guess it's akin to having people when dealing with some health dataset then getting more general from there. 14 initial features total. Depending upon what we do with this data, we'd likely set price as the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2eac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phew, no nulls. Nothing else to say about that. Always a good policy to check though.\n"
     ]
    }
   ],
   "source": [
    "if sum(df.isnull().sum())==0:\n",
    "    print(\"Phew, no nulls. Nothing else to say about that. Always a good policy to check though.\")\n",
    "else:\n",
    "    print(\"Oh boy, we got some nulls to deal with. Let's get into the 'damage'.\")\n",
    "    print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b5c03",
   "metadata": {},
   "source": [
    "Honstly a shame in this case as I was hoping to also demo null handling. Oh well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c0f15",
   "metadata": {},
   "source": [
    "## Initial EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f4e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbfa911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 0, date.\n",
      "~~~\n",
      "date\n",
      "2024-07-30    248\n",
      "2024-06-16    247\n",
      "2023-08-02    247\n",
      "2023-08-31    246\n",
      "2023-11-20    244\n",
      "             ... \n",
      "2022-02-24     13\n",
      "2022-01-24     13\n",
      "2022-02-27     13\n",
      "2022-01-22     12\n",
      "2022-01-21      8\n",
      "Name: count, Length: 1076, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(df[df.columns[i]].value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badcb677",
   "metadata": {},
   "source": [
    "Oh wow, they almost had a sale every single day in the three year period. So, they're obviously open every day of the week. Oh interesting, it seems that the first recorded data wasn't even until 2022-1-21. So, considering that February 2024 was a leap year then they had at last one sale every single day. Regardless, let's still figure out trends - weekday, month, year, and seasonal. Holidays might still affect sales too, but I doubt I'll get into that when this is just a demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59046c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 1, sku.\n",
      "~~~\n",
      "sku has 30 categories.\n",
      "sku\n",
      "MI-006    0.043097\n",
      "MI-026    0.043071\n",
      "YO-029    0.041461\n",
      "YO-005    0.041377\n",
      "YO-012    0.040465\n",
      "RE-004    0.040067\n",
      "YO-014    0.039999\n",
      "YO-001    0.039705\n",
      "RE-007    0.039259\n",
      "RE-015    0.038615\n",
      "MI-023    0.037755\n",
      "JU-021    0.036397\n",
      "YO-009    0.035532\n",
      "SN-027    0.033734\n",
      "YO-003    0.033241\n",
      "MI-022    0.032759\n",
      "YO-016    0.031406\n",
      "RE-025    0.031401\n",
      "SN-010    0.030772\n",
      "RE-017    0.030133\n",
      "SN-013    0.028838\n",
      "YO-020    0.028392\n",
      "SN-019    0.027412\n",
      "MI-002    0.026563\n",
      "MI-011    0.025493\n",
      "YO-024    0.025425\n",
      "MI-008    0.025042\n",
      "SN-028    0.024896\n",
      "YO-018    0.024146\n",
      "SN-030    0.023548\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb270e",
   "metadata": {},
   "source": [
    "Retroactively, from the segment section:<br>\n",
    "mi - milk<br>\n",
    "yo - yogurt<br>\n",
    "re - ready meal<br>\n",
    "sn - snack bar<br>\n",
    "ju - juice<br>\n",
    "\n",
    "\n",
    "\n",
    "Somewhat evenly distributed where no one-product dominates. Ie even the smallest is not so much undersold than the top milk products. Also, we didn't even consider their price, rate of consumption, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e943563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 2, brand.\n",
      "~~~\n",
      "brand has 14 categories.\n",
      "brand\n",
      "SnBrand2    0.140362\n",
      "YoBrand4    0.116992\n",
      "YoBrand3    0.099504\n",
      "MiBrand3    0.095556\n",
      "YoBrand2    0.090948\n",
      "ReBrand4    0.077874\n",
      "YoBrand1    0.073706\n",
      "MiBrand1    0.068590\n",
      "ReBrand2    0.061534\n",
      "MiBrand4    0.043071\n",
      "ReBrand1    0.040067\n",
      "JuBrand3    0.036397\n",
      "SnBrand3    0.028838\n",
      "MiBrand2    0.026563\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f71d07",
   "metadata": {},
   "source": [
    "I'm unsure if brands do multiple things - ie does milk brand 1 also sell yogurt (under brand 1)? Anyways, of interest later will be to formula add them together and compare stuff. Ie Sn, whatever that is, clearly win ovrall. Yet how much within their own sn department do they dominate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e5dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 3, segment.\n",
      "~~~\n",
      "segment has 13 categories.\n",
      "segment\n",
      "Yogurt-Seg1       0.140760\n",
      "Yogurt-Seg3       0.130071\n",
      "Milk-Seg2         0.126365\n",
      "Yogurt-Seg2       0.110318\n",
      "Milk-Seg3         0.080852\n",
      "ReadyMeal-Seg1    0.077874\n",
      "SnackBar-Seg1     0.075856\n",
      "ReadyMeal-Seg2    0.070199\n",
      "SnackBar-Seg2     0.059610\n",
      "Juice-Seg3        0.036397\n",
      "SnackBar-Seg3     0.033734\n",
      "ReadyMeal-Seg3    0.031401\n",
      "Milk-Seg1         0.026563\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d0081",
   "metadata": {},
   "source": [
    "Hmm, what did this really change? Regardless, we at least see a formal clarification of each thing now.<br><br>\n",
    "Yeah, I'm honestly unsure at the moment how these segments are working. Ie from a quick scan above (in the brand sectin) yogurts took up approximately 40% of sales. That is still true now, yet earlier it was with 4 brands and here with just 3 categories that don't appear to be sums of the more granular brand. So, brand, as an analogy Greek Yogurt, does not seem to be a complete sub-category of whatever segment is. Per a ChatGPT query it would seem to be which type of yogurt ie vanilla, chocolate, etc.. Hence, evrythingmaks sense.\n",
    "<br> But maybe not - there only appears to be one type of juice.... and it's assigned to segment3. So, that seem to imply Seg3 across the 5 items (yogurt, milk, readymeal, snackbar, and juice) are similar in flavor/type. So too regarding Seg1 and 2, seemingly.\n",
    "<br><br>\n",
    "Let this be a great example of the utility of domain knowledge. However, I'd say I'm doing pretty welll looking at this type of data professionally for the first time ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a7c475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 4, category.\n",
      "~~~\n",
      "category has 5 categories.\n",
      "category\n",
      "Yogurt       0.381150\n",
      "Milk         0.233779\n",
      "ReadyMeal    0.179474\n",
      "SnackBar     0.169200\n",
      "Juice        0.036397\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01647a1",
   "metadata": {},
   "source": [
    "Unsurprising to me that yogurt is the most purchased item per buying habbits and then milk per that and preservability. A bit surpised that snack bars aren't higher and likely now I can accurately transition into an interesting observation about this dataset - we're in Pland. Oh, I think I already mentioned that. Regardless, it's true - likely their eating (as well as perhaps the raw status of yogurt for example - maybe it's just a lot better over there, let alone cultural differences that may exist and the like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e25cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 5, channel.\n",
      "~~~\n",
      "channel has 3 categories.\n",
      "channel\n",
      "Retail        0.333870\n",
      "E-commerce    0.333508\n",
      "Discount      0.332622\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac87382",
   "metadata": {},
   "source": [
    "About as even as you can get. Potentially might drop for simplicity, but perhaps across all facets it's not even. Ie maybe all snacks are retail, reflecting the spurious nature of snacking's definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee85322f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 6, region.\n",
      "~~~\n",
      "region has 3 categories.\n",
      "region\n",
      "PL-North      0.333644\n",
      "PL-South      0.333235\n",
      "PL-Central    0.333120\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745644ce",
   "metadata": {},
   "source": [
    "I'm also surprised that this is even. Albeit synthetic, but shocking. Yet, once again, specific products or prices might be skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc1a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 7, pack_type.\n",
      "~~~\n",
      "pack_type has 3 categories.\n",
      "pack_type\n",
      "Carton       0.333781\n",
      "Multipack    0.333146\n",
      "Single       0.333073\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182ef89",
   "metadata": {},
   "source": [
    "See above. Particularly when it would come to product ie milk I'd expect to see less multi-pack. Also curious if price would be correspondingly adjusted. I guess either-way, whethr price is gross or per-unit the point would be the same to except proportionally higher rates for singles. Cartons likely slightly lwoer and the cheapest being multi-pack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9c1016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 8, price_unit.\n",
      "~~~\n",
      "count    190757.000000\n",
      "mean          5.251979\n",
      "std           2.166705\n",
      "min           1.500000\n",
      "25%           3.380000\n",
      "50%           5.250000\n",
      "75%           7.130000\n",
      "max           9.000000\n",
      "Name: price_unit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9b843",
   "metadata": {},
   "source": [
    "Oh, yeah I guess they did go into 'unit' specificity. Honestly, I don't think I like that as $24/24 /= $1/1 as it still requires that spending of $24 for that one type of item. What are people's budgets? What is the life now for all of them to be used by this one customer?\n",
    "\n",
    "Later we'll look into average yogurt... and the various devisions. I think for my sake we'll move this to the end for aesthetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41c55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 9, promotion_flag.\n",
      "~~~\n",
      "promotion_flag has 2 categories.\n",
      "promotion_flag\n",
      "0    0.8508\n",
      "1    0.1492\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec212d44",
   "metadata": {},
   "source": [
    "Seemingly if there was an add for the item - and phew it's not even.\n",
    "\n",
    "Likely the item is new (unsure if we can confirm that from the data), not as popular (motivate sales), popular (potentially - ride the gravy train), and/or expensive. I mean, ultimately they hope to make money, so presumably whatever the sku's comparative features are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350905ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 10, delivery_days.\n",
      "~~~\n",
      "delivery_days has 5 categories.\n",
      "delivery_days\n",
      "4    0.202278\n",
      "5    0.200286\n",
      "1    0.199883\n",
      "3    0.199327\n",
      "2    0.198226\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7e80d",
   "metadata": {},
   "source": [
    "To the store or to the consumer? Seemingly to the store as recall 1/3 of the sales were retail. I'm unaware of the trucking and preserving process in general (let alone Poland) yet would ventue to still assume milk then yogurt would likely be the most affected by this. Unsure if juice or snack bars are even refridgerated at all. I'd also aassume, which I may be wrong, that the meals are frozen and likely have accomodating features to maintain that; eh, they're called 'ready meals' so likely at most refridgerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f74008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 11, stock_available.\n",
      "~~~\n",
      "count    190757.000000\n",
      "mean        157.697652\n",
      "std          52.736104\n",
      "min         -12.000000\n",
      "25%         124.000000\n",
      "50%         155.000000\n",
      "75%         192.000000\n",
      "max         405.000000\n",
      "Name: stock_available, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb6a01",
   "metadata": {},
   "source": [
    "Was this at the store? Ie 405 yogurts (example) on any one given transaction opportunity? Yeah, really unsure about this one. I do not see ay other infomation about this on Kaggle.\n",
    "\n",
    "Hmm, and we have -12 for the minimum. Will likely need to change that. Presumably it was 12; well, maybe not. Perhaps they were supposed to bring 12 more than they had. So too below for delivred quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2626fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 12, delivered_qty.\n",
      "~~~\n",
      "count    190757.000000\n",
      "mean        179.333655\n",
      "std          40.037475\n",
      "min         -11.000000\n",
      "25%         152.000000\n",
      "50%         179.000000\n",
      "75%         206.000000\n",
      "max         366.000000\n",
      "Name: delivered_qty, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f9935b",
   "metadata": {},
   "source": [
    "Hmm, seemingly related as they have similar yet smaller numbers. Of interest is that the mean (and median) is much highr for delivered though, implying that (given there's an order) it's a pretty sizable amount of the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbfc1138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at feature 13, units_sold.\n",
      "~~~\n",
      "count    190757.000000\n",
      "mean         19.919709\n",
      "std          11.770077\n",
      "min         -25.000000\n",
      "25%          12.000000\n",
      "50%          18.000000\n",
      "75%          25.000000\n",
      "max         139.000000\n",
      "Name: units_sold, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(f\"Now looking at feature {i}, {df.columns[i]}.\")\n",
    "nulls = df[df.columns[i]].isnull().sum()\n",
    "if nulls > 0:\n",
    "    print(f\"Reminder that {df.columns[i]} has {nulls} nulls - deal with them noob.\")\n",
    "print('~~~')\n",
    "if len(df[df.columns[i]].value_counts()) > 10 and df[df.columns[i]].dtype in ['int64', 'float64']: #Arb. threshold\n",
    "    print(df[df.columns[i]].describe()) #note that display could be another option.\n",
    "else:\n",
    "    print(f\"{df.columns[i]} has {df[df.columns[i]].value_counts().count()} categories.\")\n",
    "    print(df[df.columns[i]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399092f3",
   "metadata": {},
   "source": [
    "Hmm, I'm guessing this is for the entire day. Also, bear in mind the multi-pack discussion.... We might change our minds once we see the prices though.\n",
    "<br><br>\n",
    "I'm guessing any negatives are a sign of returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffcc649",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Well, at least round I of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21b022e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 0         2022-01-21\n",
       "1         2022-01-21\n",
       "2         2022-01-21\n",
       "3         2022-01-21\n",
       "4         2022-01-21\n",
       "             ...    \n",
       "190752    2024-12-31\n",
       "190753    2024-12-31\n",
       "190754    2024-12-31\n",
       "190755    2024-12-31\n",
       "190756    2024-12-31\n",
       "Name: date, Length: 190757, dtype: object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7d6c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep data whole, but break into weekday, month, and of couse year.\n",
    "\n",
    "#Not going to bother to analyze Polish holidays when this is a demo, but will at least take note of them.\n",
    "#and obviously re-analyze/analyze when tehy'e actualy made\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['weekday']   = df['date'].dt.day_name()\n",
    "df['monthday']  = df['date'].dt.day\n",
    "df['month']     = df['date'].dt.month_name() \n",
    "df['year']      = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a494a63",
   "metadata": {},
   "source": [
    "Now let's formally look at the date components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df1c8a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekday\n",
       "Monday       0.143764\n",
       "Sunday       0.143224\n",
       "Tuesday      0.143224\n",
       "Saturday     0.142632\n",
       "Thursday     0.142553\n",
       "Wednesday    0.142485\n",
       "Friday       0.142118\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weekday'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f7806",
   "metadata": {},
   "source": [
    "Unsurprising given the observations earlir the near even split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5ef9db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monthday\n",
      "28    0.033315\n",
      "24    0.033304\n",
      "27    0.033299\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "monthday\n",
       "31    0.019323\n",
       "30    0.031108\n",
       "5     0.032041\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['monthday'].value_counts(normalize=True, ascending=False)[:3])\n",
    "\n",
    "df['monthday'].value_counts(normalize=True, ascending=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167af4e",
   "metadata": {},
   "source": [
    "Recall that we don't always have day 31 in the Gregorian calendar. Otherwise, essentially evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b4a124e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "December     0.099021\n",
       "October      0.094445\n",
       "November     0.093192\n",
       "August       0.090728\n",
       "July         0.089795\n",
       "September    0.088877\n",
       "May          0.085077\n",
       "June         0.084878\n",
       "April        0.076044\n",
       "March        0.070996\n",
       "January      0.064585\n",
       "February     0.062362\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab10092",
   "metadata": {},
   "source": [
    "Hmmm,  we are dfinitly seeing some trends here. Hence the time series function. What's shocking is that it'snot even seasonal but seeemingly calendar as the earlier months floundr (all 3, in fact) and the later months spike up. Perhaps holidays justify that trend. Regardless, it's shocking. Furthermore, the trend continues as the next fewest months of sales are the next three months in the calendar!\n",
    "<br>\n",
    "It's definitly incumbent upon us to explore months with any other features. Of note also is that it's not perfectly calendar. Ie dec oct nov vs. dec nov oct, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e23837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2024    0.440141\n",
       "2023    0.406533\n",
       "2022    0.153326\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea8433",
   "metadata": {},
   "source": [
    "Hmm, what happened in 2022? Definitely warrants attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e0c45",
   "metadata": {},
   "source": [
    "### Getting the various features data-ready\n",
    "\n",
    "Actually, I might skip this if I don't decide to actually model as it'll make it easier for data visualziation purposes, which is what I'm going for right now, to leave them as is.\n",
    "\n",
    "On the to-do list would be:\n",
    "\n",
    "Categorical to dummify: category, channel, region, pack_type, weekday, month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a75bd",
   "metadata": {},
   "source": [
    "Hmm, when it comes to sku, brands, segments...yeah, we'd also need to dummify them as ultimately leaving them as numbers would also skew any models as there's no inherent link between one sku being ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bbf4a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>segment</th>\n",
       "      <th>category</th>\n",
       "      <th>channel</th>\n",
       "      <th>region</th>\n",
       "      <th>pack_type</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>delivery_days</th>\n",
       "      <th>stock_available</th>\n",
       "      <th>delivered_qty</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>weekday</th>\n",
       "      <th>monthday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>price_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Retail</td>\n",
       "      <td>PL-Central</td>\n",
       "      <td>Multipack</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>128</td>\n",
       "      <td>9</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Retail</td>\n",
       "      <td>PL-North</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Retail</td>\n",
       "      <td>PL-South</td>\n",
       "      <td>Carton</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>161</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Discount</td>\n",
       "      <td>PL-Central</td>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>MI-006</td>\n",
       "      <td>MiBrand1</td>\n",
       "      <td>Milk-Seg3</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Discount</td>\n",
       "      <td>PL-North</td>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>204</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>7.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     sku     brand    segment category   channel      region  \\\n",
       "0 2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk    Retail  PL-Central   \n",
       "1 2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk    Retail    PL-North   \n",
       "2 2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk    Retail    PL-South   \n",
       "3 2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk  Discount  PL-Central   \n",
       "4 2022-01-21  MI-006  MiBrand1  Milk-Seg3     Milk  Discount    PL-North   \n",
       "\n",
       "   pack_type  promotion_flag  delivery_days  stock_available  delivered_qty  \\\n",
       "0  Multipack               0              1              141            128   \n",
       "1     Single               1              3                0            129   \n",
       "2     Carton               0              5              118            161   \n",
       "3     Single               0              2               81            114   \n",
       "4     Single               0              4              148            204   \n",
       "\n",
       "   units_sold weekday  monthday    month  year  price_unit  \n",
       "0           9  Friday        21  January  2022        2.38  \n",
       "1           0  Friday        21  January  2022        1.55  \n",
       "2           8  Friday        21  January  2022        4.00  \n",
       "3           7  Friday        21  January  2022        5.16  \n",
       "4          12  Friday        21  January  2022        7.66  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Per my aesthetics:\n",
    "\n",
    "df_cleaned =  df.drop(['price_unit'], axis = 1)\n",
    "df_cleaned['price_unit'] = df['price_unit']\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127b0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734573e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fcd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ea2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173331c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec645b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfa0f799",
   "metadata": {},
   "source": [
    "TO do later\n",
    "\n",
    "Aalyze brands\n",
    "\n",
    "eye out for:\n",
    "years, monnths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ede20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
